{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3ACJKcTItd9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# --- Step 1: Load and Analyze Data ---\n",
        "file_name = '/content/preprocessed_diabetes_data.csv'\n",
        "df = pd.read_csv(file_name)\n",
        "print(f\"Successfully loaded '{file_name}'\")\n",
        "\n",
        "# --- Data Diagnosis ---\n",
        "print(\"\\n--- Data Diagnosis ---\")\n",
        "target_counts = df['Diabetes_Diagnosis'].value_counts()\n",
        "print(\"Distribution of Target Variable ('Diabetes_Diagnosis'):\")\n",
        "print(target_counts)\n",
        "print(\"----------------------\\n\")\n",
        "\n",
        "# --- Step 2: Prepare Data ---\n",
        "y = df['Diabetes_Diagnosis']\n",
        "X = df.drop('Diabetes_Diagnosis', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Step 3: Scale Data ---\n",
        "scaler = StandardScaler()\n",
        "columns_to_scale = ['Age', 'BMI']\n",
        "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
        "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
        "\n",
        "# --- Step 4: Calculate Class Weights ---\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i : weights[i] for i in range(len(weights))}\n",
        "print(f\"Calculated Class Weights: {class_weights}\")\n",
        "\n",
        "# --- Step 5: Build and Compile Model ---\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'), Dropout(0.3),\n",
        "    Dense(16, activation='relu'), Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.summary()\n",
        "custom_optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- Step 6: Train the Model ---\n",
        "print(\"\\nStarting model training...\")\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=150, batch_size=20,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- Step 7: Evaluate the Final Model ---\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nFinal Model Evaluation:\")\n",
        "print(f\"  - Test Loss: {loss:.4f}\")\n",
        "print(f\"  - Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# --- Step 8: Save Model, Scaler, and History (History part is re-added) ---\n",
        "print(\"\\nSaving all artifacts...\")\n",
        "model.save('diabetes_model.keras')\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "# Convert the history object to a DataFrame and save it as a CSV\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.to_csv('training_history.csv', index=False)\n",
        "print(\"Model, scaler, and training history saved successfully.\")\n",
        "\n",
        "print(\"\\nTraining script finished.\")"
      ]
    }
  ]
}